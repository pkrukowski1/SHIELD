method: grid
metric:
  name: avg_acc
  goal: maximize

parameters:

  dataset:
    value: split_cifar_100
  method:
    value: shield
  model:
    value: alexnet
  exp:
    value: interval_training

  # Dataset (fixed)
  dataset._target_:
    value: continual_dataset.SplitCIFAR100
  dataset.number_of_tasks:
    value: 10
  dataset.validation_size:
    value: 500
  dataset.use_augmentation: 
    value: False
  dataset.use_cutout: 
    value: False

  # Experiment setup
  exp.seed:
    value: 1
  exp.batch_size:
    value: 32
  exp.no_epochs:
    value: 200
  exp.no_iterations:
    value:

  # Fabric setup
  fabric.accelerator:
    value: gpu

  # Method (sweep these)
  method.lr:
    value: 0.001
  method.beta:
    value: 0.01
  method.mixup_alpha:
    value: 0.3
  method.epsilon:
    value: 0.005
  method.use_lr_scheduler:
    value: True
  method.mixup_epsilon_decay:
    values: [linear, quadratic, log, cos]
  method._target_:
    value: method.SHIELD

  # Model
  model._target_:
    value: model.HyperNetWithAlexNet
  model.in_shape:
    value: [32,32,3]
  model.no_classes_per_task:
    value: 10
  model.activation_function._target_:
    value: torch.nn.ReLU
  model.hnet_hidden_layers:
    value: [100, 50]
  model.hnet_embedding_size:
    value: 512

  # W&B logging
  wandb.entity:
    value: ${oc.env:WANDB_ENTITY}
  wandb.project:
    value: ${oc.env:WANDB_PROJECT}

command:
  - ${env}
  - python
  - src/main.py
  - --config-name
  - shield.yaml
  - ${args_no_hyphens}
